{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Olist E-Commerce Website Data Analysis \n\nDataset link: https://www.kaggle.com/olistbr/brazilian-ecommerce"},{"metadata":{},"cell_type":"markdown","source":"## Table of content:\n### Setting up:\n* Importing Libraries\n\n\n* Loading the Datasets and Data Cleaning\n\n### Visualization and Data Insights:\n\n\n\n* Boxplot For The Product Weights and Freight Value (Univariable)\n\n\n* General Exploration Histogram Over All Dataframe Features (Univariable)\n\n\n* What Is The Most Frequent Payment Type ? (Univariable)\n\n\n* Payment Value Distribution Per Customer (Univariable)\n\n\n* Freight Value Vs. Product Weight Scatterplot (Bivariable)\n\n\n* What Is The Most Frequent Customer State ? (Bivariable)\n\n\n* What Is The Most In Demand Product Category ? (Bivariable)\n\n\n* What I The Most Highly Rated Product Category ? (Bivariable)\n\n\n* what Is The Nicest Customer State ? (Bivariable)\n\n\n* Payment Vs. Freight value (Bivariable)\n\n\n* Payment Value Vs. Months vs. Year (Multivariable)\n\n\n* Correlogram of Olist Master Dataframe (Multivariable)\n\n\n\n### Machine Learning Application\n\n* Clustering Customers Based On Review Rating and Purchase Power (Unsupervised Learning)\n"},{"metadata":{},"cell_type":"markdown","source":"### Importing Libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.cluster import KMeans\nfrom sklearn.preprocessing import scale\nfrom sklearn.preprocessing import normalize\nfrom sklearn.metrics import r2_score, confusion_matrix\nimport datetime\nimport random\n\n\n%matplotlib inline\nsns.set()\npd.options.display.max_columns = None","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Loading the Data"},{"metadata":{},"cell_type":"markdown","source":"#### customers_dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"# no nulls\ncustomers_dataset_df = pd.read_csv('/kaggle/input/brazilian-ecommerce/olist_customers_dataset.csv')\ncustomers_dataset_df_clean = customers_dataset_df.copy()\n\ncustomers_dataset_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### geolocation_dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"# no nulls\ngeolocation_dataset_df = pd.read_csv('/kaggle/input/brazilian-ecommerce/olist_geolocation_dataset.csv')\ngeolocation_dataset_df_clean = geolocation_dataset_df.copy()\n\ngeolocation_dataset_df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### order_items"},{"metadata":{"trusted":true},"cell_type":"code","source":"# no nulls\n\norder_items_df = pd.read_csv('/kaggle/input/brazilian-ecommerce/olist_order_items_dataset.csv')\norder_items_df_clean = order_items_df.copy()\n\norder_items_df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### order_payments"},{"metadata":{"trusted":true},"cell_type":"code","source":"# no nulls\norder_payments_dataset_df = pd.read_csv('/kaggle/input/brazilian-ecommerce/olist_order_payments_dataset.csv')\norder_payments_dataset_df_clean = order_payments_dataset_df.copy()\n\norder_payments_dataset_df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### order_reviews_dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"# review_comment_title and review_comment_message fields are empty which is fine, we will not be using them in out analysis so\n# we will drop the columns in addition to review_creation_date and review_answer_timestamp columns\norder_reviews_dataset_df = pd.read_csv('/kaggle/input/brazilian-ecommerce/olist_order_reviews_dataset.csv')\norder_reviews_dataset_df_clean = order_reviews_dataset_df.copy()\n\norder_reviews_dataset_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"order_reviews_dataset_df_clean.drop(columns = ['review_comment_title','review_comment_message','review_creation_date','review_answer_timestamp'], inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"order_reviews_dataset_df_clean.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"order_reviews_dataset_df_clean.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"order_reviews_dataset_df_clean.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### orders_dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"# 1.we will be assessing if our estimation on the order_estimated_delivery_date is correct most of the time or not, so in this casr\n# we will create a df that has only the timestamps and dates and we will be dropping this nan values to do so, that is so we \n# do not loose data for other operations from the original dataframe.\n# 2. we need to change  the data type of the dates to datetime.\norders_dataset_df = pd.read_csv('/kaggle/input/brazilian-ecommerce/olist_orders_dataset.csv')\norders_dataset_df_clean = orders_dataset_df.copy()\norders_dataset_df.info()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"orders_dataset_df_clean.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ['order_purchase_timestamp', 'order_approved_at', 'order_delivered_carrier_date', 'order_delivered_customer_date', 'order_estimated_delivery_date']\norder_datetime_list = ['order_purchase_timestamp', 'order_approved_at',\\\n                       'order_delivered_carrier_date', 'order_delivered_customer_date',\\\n                       'order_estimated_delivery_date']\n\n\norders_dataset_df_clean[order_datetime_list] = orders_dataset_df_clean[order_datetime_list].apply(pd.to_datetime, errors = 'coerce')\norders_dataset_df_clean.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# testing\norders_dataset_df_clean.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking valid values for order_status\norders_dataset_df_clean.order_status.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking if for the delivered items we have the all the timings, the invoiced only can have nan values it is fine for the dates variables.\n# we can see that we still have missing dates for already delivered orders, we can investigate closely in the company to see why we are missing these dates.\n\norders_dataset_df_clean.query(\"order_status in 'delivered'\").isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# getting the indexes of the columns that have a delivered order_status and a null order_approved_at because it does not make sense\ndelivered_and_not_approved_indexes = orders_dataset_df_clean[orders_dataset_df_clean['order_approved_at'].isnull()].query(\"order_status in 'delivered'\").index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"orders_dataset_df_clean.drop(inplace = True, index = delivered_and_not_approved_indexes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"orders_dataset_df_clean.query(\"order_status in 'delivered'\").isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### products_dataset"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"products_dataset_df = pd.read_csv('/kaggle/input/brazilian-ecommerce/olist_products_dataset.csv')\nproducts_dataset_df_clean = products_dataset_df.copy()\n\nproducts_dataset_df.info()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# we will be dropping the rows that have missing product_category_name, product_name_lenght, product_description_lenght, product_photos_qty\n# which are 610 rows of 32951\nproducts_dataset_df_clean[products_dataset_df_clean['product_category_name'].isnull()].shape\nnull_products_indexes = products_dataset_df_clean[products_dataset_df_clean['product_category_name'].isnull()].index\nproducts_dataset_df_clean.drop(inplace = True, index = null_products_indexes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# testing\nprint(products_dataset_df_clean.shape[0],products_dataset_df.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 1 row missing dimensions, we will drop it also since it has negligible effect on our analysis\nproducts_dataset_df_clean.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"additional_products_missing_g_indexes = products_dataset_df_clean[products_dataset_df_clean['product_weight_g'].isnull()].index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"products_dataset_df_clean.drop(inplace = True, index = additional_products_missing_g_indexes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"products_dataset_df_clean.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"products_dataset_df_clean.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### sellers_dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"# no missing values\nsellers_dataset_df = pd.read_csv('/kaggle/input/brazilian-ecommerce/olist_sellers_dataset.csv')\nsellers_dataset_df_clean = sellers_dataset_df.copy()\n\nsellers_dataset_df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### product_category_name_translation"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"product_category_name_translation_df = pd.read_csv('/kaggle/input/brazilian-ecommerce/product_category_name_translation.csv')\nproduct_category_name_translation_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# creating a master dataframe, that has all the clean dataframes to get more insights when we want to visualize, model and predict\nmaster_df = orders_dataset_df_clean.copy()\n\nmaster_df = master_df.merge(customers_dataset_df_clean, on='customer_id', indicator=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"master_df = master_df.merge(order_reviews_dataset_df_clean, on='order_id')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"master_df = master_df.merge(order_payments_dataset_df_clean, on='order_id')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"master_df = master_df.merge(order_items_df_clean, on = 'order_id')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"master_df = master_df.merge(products_dataset_df_clean, on = 'product_id')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"master_df = master_df.merge(sellers_dataset_df_clean, on = 'seller_id')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"master_df.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exploratory Data Visualization\n\n#### In this section we will be answering inquiries using visualizations of data insights using univariable, bivariable and multivariable plots"},{"metadata":{"trusted":true},"cell_type":"code","source":"master_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# we only have two columns having null values, order_delivered_carrier_date and order_delivered_customer_date  \nmaster_df.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,10))\nsns.heatmap(master_df.corr().round(2), xticklabels=master_df.corr().columns, yticklabels=master_df.corr().columns, cmap='RdYlGn', center=0, annot=True)\n\nplt.title('Correlogram of Olist Master Dataframe', fontsize=22)\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"master_df.corr().round(2)> 0.5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"abs(master_df.corr().round(2))>0.5","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"# we can see some correlation between our variables, we will use > 0.5 correlation to get a clearer view in our exploration\n\nplt.figure(figsize=(12,10))\nsns.heatmap(abs(master_df.corr().round(2))>0.5 , xticklabels=master_df.corr().columns, yticklabels=master_df.corr().columns, cmap='RdYlGn', center=0, annot=True)\n\nplt.title('Simplified Correlogram of Olist Master Dataframe', fontsize=22)\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list_of_correlated_columns = []\n\nfor i in (abs(master_df.corr().round(2))>0.5).columns:\n    for j in (abs(master_df.corr().round(2))>0.5).columns:\n        if ((abs(master_df.corr().round(2))>0.5).loc[i,j] == True):\n            list_of_correlated_columns.append((i,j))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(list_of_correlated_columns[0][0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# gettng rid of the pairs constructed of the same variables\nlist_of_correlated_columns_not_same = []\n\nfor k in range(len(list_of_correlated_columns)):\n    if list_of_correlated_columns[k][0] != list_of_correlated_columns[k][1]:\n        list_of_correlated_columns_not_same.append((list_of_correlated_columns[k][0], list_of_correlated_columns[k][1]))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list_of_correlated_columns_not_same","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"# since we have see correlation between the product_weight_g and freight_value in the heatmap we will be drawing\n# scatter plot with a regression line.\n\nplt.figure(figsize=(14,8))\n\nproduct_weight_g_reg = master_df.groupby('customer_id').sum()[['product_weight_g','freight_value']].reset_index()['product_weight_g']\nfreight_value_reg = master_df.groupby('customer_id').sum()[['product_weight_g','freight_value']].reset_index()['freight_value']\nsns.regplot(x=product_weight_g_reg, y=freight_value_reg, scatter_kws={'alpha':0.7, 'color':'skyblue'},\\\n           line_kws={'color':'red'});\n\nplt.title('Freight Value Vs. Product Weight Scatterplot'.title(), fontsize=22)\nplt.xlabel('Product Weight'.title(), fontsize=15)\nplt.ylabel('Freight Value'.title(), fontsize=15)\n\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(14,8))\n\nproduct_weight_g_reg = master_df.groupby('customer_id').sum()[['product_weight_g','freight_value']].reset_index()['product_weight_g']\nfreight_value_reg = master_df.groupby('customer_id').sum()[['product_weight_g','freight_value']].reset_index()['freight_value']\nsns.regplot(x=product_weight_g_reg, y=freight_value_reg, scatter_kws={'alpha':0.7, 'color':'skyblue'},\\\n           line_kws={'color':'red'});\n\nplt.xlim(0, 200000)\n\nplt.title('Freight Value Vs. Product Weight Scatterplot'+'\\n'+'Zoomed on Product Weight Between 0g and 200000g', fontsize=22)\nplt.xlabel('Product Weight'.title(), fontsize=15)\nplt.ylabel('Freight Value'.title(), fontsize=15)\n\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# alot of outliers for the product weight\nplt.figure(figsize=(14,8))\nsns.boxplot(x=product_weight_g_reg, color='skyblue');\n\nplt.title('Boxplot For The Product Weights', fontsize=18);\nplt.xlabel('Product Weight'.title(), fontsize=12);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#taking up to the 90% quantile\nplt.figure(figsize=(14,8))\n\nsns.boxplot(x=product_weight_g_reg[product_weight_g_reg < product_weight_g_reg.quantile(0.90)], color='skyblue');\nplt.title('Boxplot For The Product Weights', fontsize=18);\nplt.xlabel('Product Weight'.title(), fontsize=12);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# altot of outliers in the freight value, we will be taking the 90% quantile\nplt.figure(figsize=(14,8))\n\nsns.boxplot(freight_value_reg, color='skyblue');\n\nplt.title('Boxplot For The Freight Value', fontsize=18);\nplt.xlabel('Freight Value'.title(), fontsize=12);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#taking up to the 90% quantile\nplt.figure(figsize=(14,8))\n\nsns.boxplot(freight_value_reg[freight_value_reg < freight_value_reg.quantile(0.90)], color='skyblue');\n\nplt.title('Boxplot For The Freight Value', fontsize=18);\nplt.xlabel('Freight Value'.title(), fontsize=12);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"weight_freight_reg = pd.DataFrame({'product_weights':product_weight_g_reg, 'freight_value':freight_value_reg})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"weight_freight_reg.iloc[:,1].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ploting the regresion line with the 90% quantile, we can still see that a linear regression does not fit it well\nplt.figure(figsize=(14,8))\n\nquantile_weight_freight_reg = weight_freight_reg[weight_freight_reg < weight_freight_reg.quantile(0.9)]\n\nsns.regplot(quantile_weight_freight_reg['product_weights'] ,quantile_weight_freight_reg['freight_value'],\\\n            scatter_kws={'alpha':0.2, 'color':'skyblue'},\\\n            line_kws={'color':'red'});\n\nplt.title('Freight Value Vs. Product Weight Scatterplot'+'\\n'+'Using 90% Quantile' , fontsize=18);\nplt.ylabel('Freight Value'.title(), fontsize=12);\nplt.xlabel('Product Weight'.title(), fontsize=12);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"# general exploration\nmaster_df.hist(figsize=(15,20), color='skyblue');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Univariable Plots\n\n* Type of payments distribution \n* Orders prices distribution \n* Count plot for states \n* Count plot for products category"},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking the payment types\nmaster_df.payment_type.unique()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"payment_type_count_plot_df = master_df[['payment_type','customer_id']].groupby(['customer_id', 'payment_type']).count().reset_index()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"# The customers seems to prefer to pay by credit card over other options\n\nplt.figure(figsize=(14,8))\n\nsns.countplot(payment_type_count_plot_df['payment_type']);\n\nplt.title('What is the most frequent payment type?'.title() , fontsize=20);\nplt.ylabel('count'.title(), fontsize=14);\nplt.xlabel('payment type'.title(), fontsize=14);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"master_df.groupby('customer_id').sum().reset_index()['payment_value'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#### the price distribution of the invoices in right skewed as we see below, if we want to display the maximum values we will end up with no insights on the graph.\n\nplt.figure(figsize=(14,8))\n\nmin_order_payment_value = min(master_df.groupby('customer_id').sum().reset_index()['payment_value'])\nmax_order_payment_value = max(master_df.groupby('customer_id').sum().reset_index()['payment_value'])\n\nbins= np.linspace(start=min_order_payment_value, stop=1400, num=50)\nplt.hist(x=np.asarray(master_df.groupby('customer_id').sum().reset_index()['payment_value']), bins=bins,\\\n         color='skyblue');\n\nplt.title('payment value distribution per customer'.title()+'\\n'+'Between 0LCU and 1,400LCU' , fontsize=20);\nplt.ylabel('count'.title(), fontsize=14, rotation=90);\nplt.xlabel('payment value'.title(), fontsize=14);\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# the price distribution of the invoices in right skewed as we see below, if we want to display the maximum values we will end up with no insights on the graph.\n\nplt.figure(figsize=(14,8))\n\nbins= np.linspace(start=1400, stop=max_order_payment_value, num=60)\nplt.hist(x=np.asarray(master_df.groupby('customer_id').sum().reset_index()['payment_value']), bins=bins,\\\n         color='skyblue');\n\nplt.xlim(0,110000);\nplt.title('payment value distribution per customer'.title()+'\\n'+'Between 1400LCU and 110,000LCU' , fontsize=20);\nplt.ylabel('count'.title(), fontsize=14);\nplt.xlabel('payment value'.title(), fontsize=14);\n","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"customer_state_count_df = master_df.groupby(['customer_id','customer_state']).count().reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(14,8))\nsns.countplot(customer_state_count_df.customer_state, order=customers_dataset_df.customer_state.value_counts().index);\n\nplt.title('What is the most frequent customer state?'.title(), fontsize=20);\nplt.ylabel('count'.title(), fontsize=14);\nplt.xlabel('customer state'.title(), fontsize=14);\n\nplt.xticks(fontsize=12)\nplt.yticks(fontsize=12)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# adding the translated product name category to the data_frame to use it in the following plots.\nmaster_df_with_product_categories = master_df.merge(product_category_name_translation_df, how='left', on='product_category_name');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(14,8))\n\nsns.countplot(master_df_with_product_categories.product_category_name_english,#\n              order=master_df_with_product_categories.product_category_name_english.value_counts().index)\n\nplt.title('What is the most in demand product category?'.title(), fontsize=20);\nplt.ylabel('count'.title(), fontsize=14);\nplt.xlabel('product category'.title(), fontsize=14);\n\nplt.xticks(rotation=90, fontsize=10);\nplt.yticks(fontsize=12)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Bivariable plots\n\n* Mean score vs products category (Bar plot)\n* Mean score vs cityÂ (Bar plot)\n* Order Price vs Freight Price (Scatter plot)"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"mean_score_vs_cat_df = master_df_with_product_categories.groupby(['product_category_name_english']).mean()['review_score'].reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The on average the best product category rating wise is that of cds_dvds_musicals, and the securit_and_services seems to have\n# the lowest rating.\n\nplt.figure(figsize=(14,8))\n\nsns.barplot(data = master_df_with_product_categories, x='product_category_name_english', y='review_score',\\\n           order = master_df_with_product_categories.groupby('product_category_name_english').mean()\\\n            .reset_index().sort_values('review_score', ascending=False)['product_category_name_english'].values,\n           errcolor = 'grey');\n\nplt.title('what is the most highly rated product category?'.title(), fontsize=20);\nplt.ylabel('Average Review Score'.title(), fontsize=14);\nplt.xlabel('Product Category'.title(), fontsize=14);\n\nplt.xticks(rotation=90, fontsize= 10);\nplt.yticks(fontsize=12)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The nicest state ? AP: macapa laranjal do jari\n\nplt.figure(figsize=(14,8))\n\nsns.barplot(data = master_df_with_product_categories, x='customer_state', y='review_score',\\\n           order = master_df_with_product_categories.groupby('customer_state').mean()\\\n            .reset_index().sort_values('review_score', ascending=False)['customer_state'].values,\n           errcolor = 'grey');\n\n\nplt.title('what is the nicest customer state?'.title(), fontsize=20);\nplt.ylabel('Average Review Score'.title(), fontsize=14);\nplt.xlabel('customer state'.title(), fontsize=14);\n\nplt.xticks(rotation=0, fontsize= 12);\nplt.yticks(fontsize=12)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# is there any relationship between the price of the order and the price of the freight? no\n\npayment_vs_freight_df = master_df_with_product_categories.groupby('customer_id').sum().reset_index()[['payment_value','freight_value']]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(14,8))\nsns.regplot(data=payment_vs_freight_df, x=payment_vs_freight_df.payment_value, y=payment_vs_freight_df.freight_value,\n            scatter_kws={'alpha':0.7, 'color':'skyblue'}, line_kws={'color':'red'});\nplt.xlim(0,20000);\n\nplt.title('Payment Vs. Freight value'.title(), fontsize=20);\nplt.ylabel('Freight value'.title(), fontsize=14);\nplt.xlabel('Payment Value'.title(), fontsize=14);\n\nplt.xticks(rotation=0, fontsize= 12);\nplt.yticks(fontsize=12)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Multivariable Plots\n* Payment value vs. month vs. year"},{"metadata":{"trusted":true},"cell_type":"code","source":"master_df_with_product_categories['year'] = pd.DatetimeIndex(master_df_with_product_categories['order_purchase_timestamp']).year","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"master_df_with_product_categories['month'] = pd.DatetimeIndex(master_df_with_product_categories['order_purchase_timestamp']).month ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"master_df_with_product_categories.groupby(['year','month']).sum()['payment_value']","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"multivariable_plot_df = master_df_with_product_categories.groupby(['year','month']).sum()['payment_value'].reset_index()\nmultivariable_plot_df\n","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"g = sns.FacetGrid(data=multivariable_plot_df, row = 'year', height=7, aspect=2.5, sharey=True)\n\ng = g.map(plt.bar, 'month', 'payment_value', color='skyblue')\ng.set_titles( size=20);\ng.set_ylabels('Payment Value'.title(), size=14);\ng.set_xlabels('months'.title(), size=14);\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Machine Learning Applications\n* Clustering customers based on customers data\n* Customer Life Time Value prediction"},{"metadata":{},"cell_type":"markdown","source":"## Clustering Customers Based On Review Rating and Purchase Power \n## (Unsupervised Learning)"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"clustering_customers_df = master_df_with_product_categories[['customer_unique_id','customer_id','payment_value','review_score']]\\\n.groupby('customer_unique_id').agg({'payment_value': 'sum', 'review_score': 'mean', 'customer_id':'count'}).reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clustering_customers_df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets check the scatter\nplt.figure(figsize=(14,8));\n\nplt.scatter( clustering_customers_df.payment_value, clustering_customers_df.review_score, color='skyblue');\nplt.xlim(0,35000);\n\n\nplt.title('Payment value vs. review score (Not Scaled)'.title(), fontsize=20);\nplt.ylabel('review score'.title(), fontsize=14);\nplt.xlabel('Payment value'.title(), fontsize=14);\n\nplt.xticks(rotation=0, fontsize= 12);\nplt.yticks(fontsize=12)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(14,8))\n\nbins= np.linspace(start=0, stop=1400, num=50)\nplt.hist(x=np.asarray(clustering_customers_df.payment_value), bins=bins, color='skyblue');\n\nplt.title('Payment value distribution'.title(), fontsize=20);\nplt.ylabel('count'.title(), fontsize=14);\nplt.xlabel('Payment value'.title(), fontsize=14);\n\nplt.xticks(rotation=0, fontsize= 12);\nplt.yticks(fontsize=12)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clustering_customers_df.payment_value.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(14,8))\nsns.scatterplot(x=scale(clustering_customers_df.payment_value), y=scale(clustering_customers_df.review_score), alpha=0.8,\\\n                x_jitter=0.5, y_jitter=0.5, s=80, data=clustering_customers_df, color='skyblue');\n\nplt.title('Payment value vs. review score (scaled)'.title(), fontsize=20);\nplt.ylabel('review score'.title(), fontsize=14);\nplt.xlabel('Payment value'.title(), fontsize=14);\n\nplt.xticks(rotation=0, fontsize= 12);\nplt.yticks(fontsize=12)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scale(clustering_customers_df.review_score).mean()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"clustering_customers_df['scaled_payment_value'] = scale(clustering_customers_df.payment_value)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clustering_customers_df['scaled_review_score'] = scale(clustering_customers_df.review_score)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"clustering_customers_df[['scaled_payment_value','scaled_review_score']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# KMeans\nkmeans = KMeans(4)\nkmeans.fit(clustering_customers_df[['scaled_payment_value','scaled_review_score']])\nclusters = clustering_customers_df[['scaled_payment_value','scaled_review_score']].copy()\nclustering_customers_df['cluster_pred'] = kmeans.fit_predict(clusters)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"clustering_customers_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(14,8))\nax = sns.scatterplot(x=scale(clustering_customers_df.payment_value), y=scale(clustering_customers_df.review_score), alpha=0.8,\\\n                x_jitter=0.5, y_jitter=0.5, hue='cluster_pred', data=clustering_customers_df,\\\n               s=80, palette=sns.color_palette(\"hls\", 4));\n\n\nplt.setp(ax.get_legend().get_title(), fontsize='25')\nplt.setp(ax.get_legend().get_texts(), fontsize='20')\nplt.title('Clustering Customers'+'\\n'+'Payment vaue vs. review score (4 clusters scaled)'.title(), fontsize=20);\nplt.ylabel('review score'.title(), fontsize=14);\nplt.xlabel('Payment value'.title(), fontsize=14);\n\nplt.xticks(rotation=0, fontsize= 12);\nplt.yticks(fontsize=12)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Implementing the Elbow Method to choose the number of clusters"},{"metadata":{"trusted":true},"cell_type":"code","source":"# The Elbow method is mainly about plotting the Within Cluster Standard Error (WCSS) vs the Number of Clusters used.\n# And we will be checking for a number of clusters that forms an elbow shape, meaning that the slope of our line changes highly when it\n# goes into the number of clusters,(Slope_line_before_x_clusters+point != Slope_line_after_x_clusters_point)\n\nwcss = []\nfor i in range(1,10):\n    kmeans = KMeans(i)\n    kmeans.fit(clustering_customers_df[['scaled_payment_value','scaled_review_score']])\n    wcss.append(kmeans.inertia_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 3 seems to have a good change in wcss, we will try it.\nplt.figure(figsize=(14,8))\n\nplt.plot(range(1,10), wcss, linewidth=4);\nplt.xlabel('Number of clusters'.title())\nplt.ylabel('wcss'.title())\n\nplt.title('WCSS vs. Number of Clusters', fontsize=20);\nplt.ylabel('WCSS', fontsize=14);\nplt.xlabel('Number of Clusters'.title(), fontsize=14);\n\nplt.xticks(rotation=0, fontsize= 12);\nplt.yticks(fontsize=12)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"kmeans_new = KMeans(3)\nkmeans_new.fit(clustering_customers_df[['scaled_payment_value','scaled_review_score']])\nclustering_customers_df['clusters_new_3'] = kmeans_new.fit_predict(clustering_customers_df[['scaled_payment_value','scaled_review_score']])\nclustering_customers_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(14,8))\nax= sns.scatterplot(x=scale(clustering_customers_df.payment_value), y=scale(clustering_customers_df.review_score), alpha=0.8,\\\n                x_jitter=0.5, y_jitter=0.5, hue='clusters_new_3', data=clustering_customers_df,\\\n               s=80, palette=sns.color_palette(\"hls\", 3));\n\n\nplt.setp(ax.get_legend().get_title(), fontsize='25')\nplt.setp(ax.get_legend().get_texts(), fontsize='20')\nplt.title('Clustering Customers'+'\\n'+'Payment value vs. review score (3 clusters scaled)'.title(), fontsize=20);\nplt.ylabel('review score'.title(), fontsize=14);\nplt.xlabel('Payment value'.title(), fontsize=14);\n\nplt.xticks(rotation=0, fontsize= 12);\nplt.yticks(fontsize=12)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# from a business point of view I believe the last cluster seem to be a group of outliers,\n#they have alot of purchase power, some of them are satistfied some are not, if we isolate this group, it is better to use 5 \n# clusters is order to have the for typical clusters: Fans, supporters, Roamers, Alienated, in addition to our case, the group of outliers\n\nkmeans_new_5 = KMeans(5)\nkmeans_new_5.fit(clustering_customers_df[['scaled_payment_value','scaled_review_score']])\nclustering_customers_df['clusters_new_5'] = kmeans_new_5.fit_predict(clustering_customers_df[['scaled_payment_value','scaled_review_score']])\nclustering_customers_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# as we see no real added value happened to our clustering of 5, which validate the Elbow method, since on the graph we do not see\n# any real change in the WCSS with the increase of number of clusters.\n\nplt.figure(figsize=(14,8))\n\nax = sns.scatterplot(x=scale(clustering_customers_df.payment_value), y=scale(clustering_customers_df.review_score), alpha=0.8,\\\n                x_jitter=0.5, y_jitter=0.5, hue='clusters_new_5', data=clustering_customers_df,\\\n               s=80, palette=sns.color_palette(\"husl\", 5));\n\n\nplt.setp(ax.get_legend().get_title(), fontsize='25')\nplt.setp(ax.get_legend().get_texts(), fontsize='20')\nplt.title('Clustering Customers'+'\\n'+'Payment value vs. review score (5 clusters scaled)'.title(), fontsize=20);\nplt.ylabel('review score'.title(), fontsize=14);\nplt.xlabel('Payment value'.title(), fontsize=14);\n\nplt.xticks(rotation=0, fontsize= 12);\nplt.yticks(fontsize=12)\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}